{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9315744,"sourceType":"datasetVersion","datasetId":5606571},{"sourceId":201126424,"sourceType":"kernelVersion"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom wgan_image_synthesis import Generator, Discriminator\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torchvision.utils as vutils\nimport torch.optim as optim\nimport torch.nn as nn\nfrom torchvision.utils import save_image","metadata":{"_uuid":"ab34e2ac-3dcc-4484-9c29-a6a79dfacfef","_cell_guid":"27892347-f893-4cb2-85d8-8fd71f3c6b0a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-14T17:43:25.780150Z","iopub.execute_input":"2024-10-14T17:43:25.780599Z","iopub.status.idle":"2024-10-14T17:43:25.787582Z","shell.execute_reply.started":"2024-10-14T17:43:25.780554Z","shell.execute_reply":"2024-10-14T17:43:25.786340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DiseaseDataset(Dataset):\n    def __init__(self, img_dir, transform=None):\n        self.img_dir = img_dir\n        self.image_files = os.listdir(img_dir)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_files)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.image_files[idx])\n        image = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        return image","metadata":{"execution":{"iopub.status.busy":"2024-10-14T17:43:03.387093Z","iopub.execute_input":"2024-10-14T17:43:03.387673Z","iopub.status.idle":"2024-10-14T17:43:03.396365Z","shell.execute_reply.started":"2024-10-14T17:43:03.387621Z","shell.execute_reply":"2024-10-14T17:43:03.395181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),      \n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalize to [-1, 1]\n])","metadata":{"execution":{"iopub.status.busy":"2024-10-14T17:43:03.397719Z","iopub.execute_input":"2024-10-14T17:43:03.398066Z","iopub.status.idle":"2024-10-14T17:43:03.411151Z","shell.execute_reply.started":"2024-10-14T17:43:03.398022Z","shell.execute_reply":"2024-10-14T17:43:03.410174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dev = 'cuda:0' if torch.cuda.is_available() else 'cpu'\ndevice = torch.device(dev)\nngpu = 2","metadata":{"execution":{"iopub.status.busy":"2024-10-14T17:43:03.414035Z","iopub.execute_input":"2024-10-14T17:43:03.414458Z","iopub.status.idle":"2024-10-14T17:43:03.478360Z","shell.execute_reply.started":"2024-10-14T17:43:03.414410Z","shell.execute_reply":"2024-10-14T17:43:03.477160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"/kaggle/input/vce-dataset/training/Erosion\"\nbatch_size = 32\nshuffle = True","metadata":{"execution":{"iopub.status.busy":"2024-10-14T17:43:03.479717Z","iopub.execute_input":"2024-10-14T17:43:03.480731Z","iopub.status.idle":"2024-10-14T17:43:03.487594Z","shell.execute_reply.started":"2024-10-14T17:43:03.480667Z","shell.execute_reply":"2024-10-14T17:43:03.486698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = DiseaseDataset(path, transform=transform)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T17:43:03.489143Z","iopub.execute_input":"2024-10-14T17:43:03.489554Z","iopub.status.idle":"2024-10-14T17:43:03.519292Z","shell.execute_reply.started":"2024-10-14T17:43:03.489511Z","shell.execute_reply":"2024-10-14T17:43:03.518452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataloader = DataLoader(dataset = dataset, batch_size = batch_size, shuffle = shuffle)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T17:43:03.520649Z","iopub.execute_input":"2024-10-14T17:43:03.521213Z","iopub.status.idle":"2024-10-14T17:43:03.525693Z","shell.execute_reply.started":"2024-10-14T17:43:03.521172Z","shell.execute_reply":"2024-10-14T17:43:03.524701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"real_batch = next(iter(dataloader))\nplt.figure(figsize = (8,8))\nplt.axis(\"off\")\nplt.title(\"Training_imgs\")\nplt.imshow(np.transpose(vutils.make_grid(real_batch.to(device), padding = 2, normalize=True).cpu(),(1,2,0)))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-14T17:43:03.526898Z","iopub.execute_input":"2024-10-14T17:43:03.527272Z","iopub.status.idle":"2024-10-14T17:43:04.770272Z","shell.execute_reply.started":"2024-10-14T17:43:03.527230Z","shell.execute_reply":"2024-10-14T17:43:04.769394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"netD = Discriminator(ngpu,64,3).to(device)\n# # Handle multi-GPU if desired\nif (device.type == 'cuda') and (ngpu > 1):\n    netD = nn.DataParallel(netD, list(range(ngpu)))\n\n# Print the model\nprint(netD)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T17:43:31.041435Z","iopub.execute_input":"2024-10-14T17:43:31.042322Z","iopub.status.idle":"2024-10-14T17:43:31.077601Z","shell.execute_reply.started":"2024-10-14T17:43:31.042267Z","shell.execute_reply":"2024-10-14T17:43:31.076601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"netG = Generator(ngpu,64,3,100).to(device)\n\n# Handle multi-GPU if desired\nif (device.type == 'cuda') and (ngpu > 1):\n    netG = nn.DataParallel(netG, list(range(ngpu)))\n\n# Print the model\nprint(netG)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T17:43:32.232496Z","iopub.execute_input":"2024-10-14T17:43:32.233521Z","iopub.status.idle":"2024-10-14T17:43:32.377652Z","shell.execute_reply.started":"2024-10-14T17:43:32.233463Z","shell.execute_reply":"2024-10-14T17:43:32.376517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def filtered_params(model):\n    return [param for name, param in model.named_parameters() if 'batch' not in name]\nparams = filtered_params(netG)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T17:43:34.137350Z","iopub.execute_input":"2024-10-14T17:43:34.137755Z","iopub.status.idle":"2024-10-14T17:43:34.143282Z","shell.execute_reply.started":"2024-10-14T17:43:34.137719Z","shell.execute_reply":"2024-10-14T17:43:34.141933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fixed_noise = torch.randn(batch_size, 100, 1,1,device = device)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T17:43:36.008093Z","iopub.execute_input":"2024-10-14T17:43:36.008544Z","iopub.status.idle":"2024-10-14T17:43:36.026738Z","shell.execute_reply.started":"2024-10-14T17:43:36.008500Z","shell.execute_reply":"2024-10-14T17:43:36.025484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"D_lr = 0.001\nG_lr = 0.001","metadata":{"execution":{"iopub.status.busy":"2024-10-14T17:43:37.541891Z","iopub.execute_input":"2024-10-14T17:43:37.542974Z","iopub.status.idle":"2024-10-14T17:43:37.550267Z","shell.execute_reply.started":"2024-10-14T17:43:37.542918Z","shell.execute_reply":"2024-10-14T17:43:37.549160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizerD = optim.RMSprop(netD.parameters(), lr = D_lr)\noptimizerG = optim.RMSprop(netG.parameters(), lr = G_lr)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T17:43:44.612192Z","iopub.execute_input":"2024-10-14T17:43:44.612557Z","iopub.status.idle":"2024-10-14T17:43:44.617729Z","shell.execute_reply.started":"2024-10-14T17:43:44.612525Z","shell.execute_reply":"2024-10-14T17:43:44.616750Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 20","metadata":{"execution":{"iopub.status.busy":"2024-10-14T17:43:46.167471Z","iopub.execute_input":"2024-10-14T17:43:46.167816Z","iopub.status.idle":"2024-10-14T17:43:46.172541Z","shell.execute_reply.started":"2024-10-14T17:43:46.167785Z","shell.execute_reply":"2024-10-14T17:43:46.171511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Starting Training Loop...\")\nimg_list = []\nG_losses = []\nD_losses = []\nD_real_losses = []\nD_fake_losses = []\niters = 0\n\nfor epoch in range(1,num_epochs+1):\n    for i, data in enumerate(dataloader, 0):\n        for _ in range (5):\n            ##train with all reals\n            netD.zero_grad()\n            #setup batch\n            real_cpu = data.to(device)\n            b_size = real_cpu.size(0)\n            \n            #fwd pass thru D\n            output = netD(real_cpu)\n            errD_real = -torch.mean(output)\n            D_x = output.mean().item()\n            ##train with all fakes\n            #gen batch of latent\n\n            noise = torch.randn(b_size, 100,1,1, device = device)\n            #generate fake batch by G\n            fake = netG(noise)\n            output = netD(fake.detach())\n            D_G_z1 = output.mean().item()\n            errD_fake = torch.mean(output)\n            #compute errD as sum of fake and real\n            errD = errD_fake + errD_real\n\n            #update D\n            errD.backward()\n            optimizerD.step()\n            \n            with torch.no_grad():\n                for name, param in netD.named_parameters():\n                    if 'batch' not in name:\n                        param.clamp_(-0.01,0.01)\n\n        \n        ############################\n        # (2) Update G network\n        ###########################\n        \n        netG.zero_grad()\n#         label.fill_(real_label)# fake labels are real for generator cost\n        noise = torch.randn(b_size, 100,1,1, device = device)\n        fake = netG(noise)\n        output = netD(fake)\n        errG = -torch.mean(output)\n#         print(errG)\n        errG.backward()\n        D_G_z2 = output.mean().item()\n        optimizerG.step()\n        \n        if i%1 == 0:\n            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n                  % (epoch, num_epochs, i, len(dataloader),\n                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n        \n        G_losses.append(errG.item())\n        D_losses.append(errD.item())\n        D_real_losses.append(errD_real.item())\n        D_fake_losses.append(errD_fake.item())\n    \n    if(epoch%5 == 0):\n        print(f\"EPOCH_{epoch} OUTPUT\")\n        with torch.no_grad():\n            fake = netG(fixed_noise).detach().cpu()\n        img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n        grid_image = vutils.make_grid(torch.cat(img_list), padding = True, normalize = True)\n        processed = np.transpose(grid_image.cpu().detach().numpy(), (1, 2, 0))\n        fig = plt.figure(figsize=(16,16))\n        plt.axis(\"off\")\n    #     ims = [[ plt.imshow(np.transpose(i,(1,2,0)), cmap = 'gray')]for i in img_list]\n        plt.imshow(np.transpose(grid_image, (1, 2, 0)))\n        plt.show()\n\n        img_list = []\n\n    iters += 1\n    ","metadata":{"execution":{"iopub.status.busy":"2024-10-14T17:43:53.893038Z","iopub.execute_input":"2024-10-14T17:43:53.893422Z","iopub.status.idle":"2024-10-14T17:43:58.144148Z","shell.execute_reply.started":"2024-10-14T17:43:53.893378Z","shell.execute_reply":"2024-10-14T17:43:58.143172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.title(\"Generator and Discriminator Loss During Training\")\nplt.plot(D_real_losses, label = \"D_real_loss\")\nplt.plot(D_fake_losses, label = \"D_fake_loss\")\nplt.plot(G_losses,label=\"G_loss\")\nplt.plot(D_losses,label=\"D_net_loss\")\nplt.xlabel(\"iterations\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-14T17:44:05.260186Z","iopub.execute_input":"2024-10-14T17:44:05.261040Z","iopub.status.idle":"2024-10-14T17:44:05.617885Z","shell.execute_reply.started":"2024-10-14T17:44:05.260981Z","shell.execute_reply":"2024-10-14T17:44:05.616940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs(\"checkpoints\",exist_ok=True)\n\nPATH = f\"/kaggle/working/checkpoints/last_GAN.pt\"\ntorch.save({\n\n    'Gen_state_dict': netG.state_dict(),\n    'Disc_state_dict': netD.state_dict(),\n    'optimizerG_state_dict': optimizerG.state_dict(),\n    'optimizerD_state_dict': optimizerD.state_dict(),\n}, PATH)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T17:44:11.320096Z","iopub.execute_input":"2024-10-14T17:44:11.320860Z","iopub.status.idle":"2024-10-14T17:44:11.500757Z","shell.execute_reply.started":"2024-10-14T17:44:11.320816Z","shell.execute_reply":"2024-10-14T17:44:11.499592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_dir = 'SynthesizedImages'\nos.makedirs(save_dir, exist_ok=True)\n\n# Number of images to generate\nn = 32\n\n# Set your generator to evaluation mode\nnetG.eval()\n\n# Generate n random latent vectors\nlatent_dim = 100  # Replace with the dimension of your latent space\nrandom_noise = torch.randn(n, latent_dim, 1, 1).to(device)  # Assuming you use 1x1 feature maps\n\n# Generate images using the generator\nwith torch.no_grad():\n    generated_images = netG(random_noise)\n\n# Denormalize the images if you used normalization during training\ngenerated_images = (generated_images + 1) / 2  # Assuming images were normalized to [-1, 1]\n\n# Save each generated image\nfor i in range(n):\n    save_image(generated_images[i], os.path.join(save_dir, f'generated_image_{i+1}.png'))","metadata":{"execution":{"iopub.status.busy":"2024-10-14T17:44:13.087747Z","iopub.execute_input":"2024-10-14T17:44:13.088648Z","iopub.status.idle":"2024-10-14T17:44:13.276832Z","shell.execute_reply.started":"2024-10-14T17:44:13.088603Z","shell.execute_reply":"2024-10-14T17:44:13.275952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r SynthesizedImages.zip SynthesizedImages ","metadata":{"execution":{"iopub.status.busy":"2024-10-14T17:43:05.252640Z","iopub.status.idle":"2024-10-14T17:43:05.253123Z","shell.execute_reply.started":"2024-10-14T17:43:05.252861Z","shell.execute_reply":"2024-10-14T17:43:05.252886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}